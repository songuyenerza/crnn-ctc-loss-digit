{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main\n",
    "import random\n",
    "import argparse\n",
    "from cgi import test\n",
    "from itertools import count\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import PIL.ImageOps\n",
    "from numpy import quantile  \n",
    "\n",
    "from get_mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from cgi import test\n",
    "from itertools import count\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import PIL.ImageOps\n",
    "from numpy import quantile  \n",
    "\n",
    "from get_mnist import load_mnist\n",
    "from num_seq_generator import generate_numbers_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100000):\n",
    "    x= random.randint(1000000,999999)\n",
    "    out_path= Path(\"D:/ANlab/sequence-generator/data\")\n",
    "    sequence= x\n",
    "    sequence = list(map(int, str(sequence)))\n",
    "    train_imgs, train_labels, _, _ = load_mnist(out_path)\n",
    "    \n",
    "    number_sequence_image = generate_numbers_sequence(\n",
    "        sequence,\n",
    "        (0,40),\n",
    "        150,\n",
    "        train_imgs,\n",
    "        train_labels,\n",
    "    )\n",
    "    im = Image.fromarray(number_sequence_image * 255)\n",
    "    im = im.convert(\"L\")\n",
    "    im = PIL.ImageOps.invert(im)\n",
    "    # print(args.sequence)\n",
    "    count= random.randint(100000000000000,999999999999999)\n",
    "    name = 'datagen_train_123456'+'/' + str(x)+\"_\" + str(count) +'.png'\n",
    "    im.save(name, quality= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dropout, Dense, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33250"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = \"D:/ANlab/sequence-generator/New_augmentation/data_train_augment_plate_num\"\n",
    "train_image_paths= []\n",
    "image_label_train=[]\n",
    "for path in os.listdir(data_folder):\n",
    "    train_image_paths.append(data_folder + \"/\" + path)\n",
    "    img_name = path[0:len(path)-20]\n",
    "    image_label_train.append(img_name)  \n",
    "\n",
    "len(image_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "CHAR_VECTOR= \"0123456789a\"\n",
    "letters = [letter for letter in CHAR_VECTOR]\n",
    "\n",
    "num_classes = len(letters) + 1\n",
    "max_text_len= 6\n",
    "img_w, img_h  = 128, 64\n",
    "\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_list = sorted(CHAR_VECTOR)\n",
    "def encode_to_labels(txt):\n",
    "\n",
    "    dig_lst = [] \n",
    "    for index, char in enumerate(txt):\n",
    "        try:\n",
    "            dig_lst.append(char_list.index(char))\n",
    "        except:\n",
    "            break\n",
    "            # print(char)\n",
    "    \n",
    "    return pad_sequences([dig_lst], maxlen=max_text_len, padding='post', value = 11)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  3 10  6  2 11]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'03a62'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_image_texts_train = list(map(encode_to_labels, image_label_train))\n",
    "\n",
    "print(padded_image_texts_train[100])\n",
    "image_label_train[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_sample(img_path, label):\n",
    "    \n",
    "    # 1. Read image\n",
    "    img = tf.io.read_file(img_path)\n",
    "\n",
    "    # 2. Decode and convert to grayscale\n",
    "    img = tf.io.decode_jpeg(img, channels=1)\n",
    "\n",
    "    # 3. Convert to float32 in [0, 1] range\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    # 4. Resize to the desired size\n",
    "    img = tf.image.resize(img, [64,128])\n",
    "    img = tf.transpose(img, perm=(1,0,2))\n",
    "    label = tf.strings.as_string(label)\n",
    "    label = tf.strings.to_number(label, tf.int32)\n",
    "    return { \"Input\": img, \"Label\": label }\n",
    "    # return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainAug = Sequential([\n",
    "\t# preprocessing.Rescaling(scale=1.0 / 255),\n",
    "\n",
    "\t# preprocessing.RandomZoom(\n",
    "\t\t# height_factor=(-0.05, -0.15),\n",
    "\t\t# width_factor=(-0.05, -0.15)),\n",
    "\t# preprocessing.RandomRotation(0.01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_image_paths, padded_image_texts_train))\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset.map(\n",
    "        process_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    # .shuffle(buffer_size=1000)\n",
    "    # .map(lambda x, y: (trainAug(x), y),\n",
    "\t# \t num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec={'Input': TensorSpec(shape=(None, 128, 64, 1), dtype=tf.float32, name=None), 'Label': TensorSpec(shape=(None, 6), dtype=tf.int32, name=None)}>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras import models\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "\n",
    "# def batch_activate(x):\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Activation('relu')(x)\n",
    "#     return x\n",
    "# def convolution_block(x,\n",
    "#                       filters,\n",
    "#                       size,\n",
    "#                       strides=(1, 1),\n",
    "#                       padding='same',\n",
    "#                       activation=True):\n",
    "#     x = layers.Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "#     if activation:\n",
    "#         x = batch_activate(x)\n",
    "#     return x\n",
    "\n",
    "# def residual_block(block_input,\n",
    "#                    num_filters=16,\n",
    "#                    use_batch_activate=False):\n",
    "#     x = batch_activate(block_input)\n",
    "#     x = convolution_block(x, num_filters, (3, 3))\n",
    "#     x = convolution_block(x, num_filters, (3, 3), activation=False)\n",
    "#     x = layers.Add()([x, block_input])\n",
    "#     if use_batch_activate:\n",
    "#         x = batch_activate(x)\n",
    "#     return x\n",
    "# def resnet_backbone(start_neurons=32,\n",
    "#                     dropout_rate=0.1):\n",
    "#     input_layer = layers.Input(\n",
    "#         name='input_image',\n",
    "#         shape=(128,32,1),\n",
    "#         dtype='float32'\n",
    "#     )\n",
    "\n",
    "#     for index, i in enumerate([1, 2, 2, 4, 8]):\n",
    "#         if index == 0:\n",
    "#             inner = input_layer\n",
    "#         inner = layers.Conv2D(start_neurons * i, (3,3),\n",
    "#                               activation=None, padding=\"same\")(inner)\n",
    "#         inner = residual_block(inner, start_neurons * i)\n",
    "#         inner = residual_block(inner, start_neurons * i, True)\n",
    "\n",
    "#         if i <=2:\n",
    "#             inner = layers.MaxPooling2D((2,2))(inner)\n",
    "\n",
    "#         if dropout_rate:\n",
    "#             inner = layers.Dropout(dropout_rate)(inner)\n",
    "    \n",
    "#     inner = Reshape(target_shape=((32,512)), name='reshape')(inner)  # (None, 32, 2048)\n",
    "#     inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)  # (None, 32, 64)\n",
    "#     inner1 = Dropout(0.1)(inner)\n",
    "\n",
    "#     x = layers.Bidirectional(\n",
    "#         layers.LSTM(units=256, return_sequences=True, dropout=0.1), name='bi_lstm1')(inner1)\n",
    "#     x = layers.Bidirectional(\n",
    "#         layers.LSTM(units=256, return_sequences=True, dropout=0.1), name='bi_lstm2')(x)\n",
    "#     x = layers.Dense(units=num_classes, name='logits')(x)\n",
    "\n",
    "    \n",
    "#     return Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "# model = resnet_backbone()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "from tensorflow.keras.layers import Reshape, Lambda, BatchNormalization\n",
    "from tensorflow.keras.layers import Add, Concatenate\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "# Build an endpoint layer for implementing CTC loss.\n",
    "class CTCLayer( layers.Layer ):\n",
    "    def __init__( self, name=None, **kwargs ):\n",
    "        super().__init__( name=name )\n",
    "        self.loss_fn = K.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Compute the training-time loss value and add it to the layer using `self.add_loss()`.\n",
    "        batch_len = tf.cast( tf.shape(y_true)[0], dtype='int64' )\n",
    "        input_length = tf.cast( tf.shape(y_pred)[1], dtype='int64' )\n",
    "        label_length = tf.cast( tf.shape(y_true)[1], dtype='int64' )\n",
    "        \n",
    "        input_length = input_length*tf.ones( shape=(batch_len,1), dtype='int64' )\n",
    "        label_length = label_length*tf.ones( shape=(batch_len,1), dtype='int64' )\n",
    "\n",
    "        loss = self.loss_fn( y_true, y_pred, input_length, label_length )\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # At test time, just return the computed predictions\n",
    "        return y_pred\n",
    "\n",
    "def get_Model(training):\n",
    "    input_shape = (128,64, 1)     # (128, 64, 1)\n",
    "    labels = Input( shape=(None,), dtype='float32', name=\"Label\" )\n",
    "    # labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n",
    "    # Make Networkw\n",
    "    inputs = Input(name='Input', shape=input_shape, dtype='float32')  # (None, 128, 64, 1)\n",
    "\n",
    "    # Convolution layer (VGG)\n",
    "    inner = Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(inputs)  # (None, 128, 64, 64)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)  # (None,64, 32, 64)\n",
    "\n",
    "    inner = Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)  # (None, 64, 32, 128)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)  # (None, 32, 16, 128)\n",
    "\n",
    "    inner = Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)  # (None, 32, 16, 256)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(inner)  # (None, 32, 16, 256)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)  # (None, 32, 8, 256)\n",
    "\n",
    "\n",
    "    inner = Conv2D(512, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(inner)  # (None, 32, 8, 512)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = Conv2D(512, (3, 3), padding='same', name='conv6')(inner)  # (None, 32, 8, 512)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(1, 2), name='max4')(inner)  # (None, 32, 4, 512)\n",
    "\n",
    "    inner = Conv2D(512, (2, 2), padding='same', kernel_initializer='he_normal', name='con7')(inner)  # (None, 32, 4, 512)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "\n",
    "\n",
    "\n",
    "    # CNN to RNN\n",
    "    inner = Reshape(target_shape=((32,2048)), name='reshape')(inner)  # (None, 32, 2048)\n",
    "    inner = Dense(128, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)  # (None, 32, 64)\n",
    "    inner1 = Dropout(0.1)(inner)\n",
    "\n",
    "\n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(units=256, return_sequences=True), name='bi_lstm1')(inner)\n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(units=256, return_sequences=True), name='bi_lstm2')(x)\n",
    "    # x = layers.Bidirectional(\n",
    "    #     layers.LSTM(units=128, return_sequences=True), name='bi_lstm3')(x)\n",
    "    x = Dense( 12, activation='softmax', name='Softmax' )(x) \n",
    "\n",
    "    output = CTCLayer( name='CTC_Loss' )(labels, x)\n",
    "\n",
    "    if training:\n",
    "      return Model( inputs=[inputs,labels], outputs=[output], name='CRNN_Model_with_CTC_LOSS' ) \n",
    "\n",
    "    \n",
    "model = get_Model(training=True)\n",
    "# model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile( optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CTCLoss(keras.losses.Loss):\n",
    "#     \"\"\" A class that wraps the function of tf.nn.ctc_loss. \n",
    "    \n",
    "#     Attributes:\n",
    "#         logits_time_major: If False (default) , shape is [batch, time, logits], \n",
    "#             If True, logits is shaped [time, batch, logits]. \n",
    "#         blank_index: Set the class index to use for the blank label. default is\n",
    "#             -1 (num_classes - 1). \n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, logits_time_major=False, name='ctc_loss'):\n",
    "#         super().__init__(name=name)\n",
    "#         self.logits_time_major = logits_time_major\n",
    "        \n",
    "#     def call(self, y_true, y_pred):\n",
    "#         \"\"\" \n",
    "#             Computes CTC (Connectionist Temporal Classification) loss. \n",
    "#         \"\"\"\n",
    "#         y_true = tf.cast(y_true, tf.int32)\n",
    "#         logit_length = tf.fill([tf.shape(y_pred)[0]], tf.shape(y_pred)[1])\n",
    "#         label_length = tf.fill([tf.shape(y_true)[0]], tf.shape(y_true)[1])\n",
    "#         loss = tf.nn.ctc_loss(\n",
    "#             labels=y_true,\n",
    "#             logits=y_pred,\n",
    "#             label_length=label_length,\n",
    "#             logit_length=logit_length,\n",
    "#             logits_time_major=self.logits_time_major,\n",
    "            \n",
    "#         )\n",
    "#         return tf.math.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = tf.distribute.get_strategy()\n",
    "# with strategy.scope():\n",
    "#     # optimizer\n",
    "#     optimizer = tf.keras.optimizers.Adam()\n",
    "#     # model=build_model()\n",
    "#     # compile\n",
    "#     model.compile(optimizer=optimizer,loss=CTCLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "520/520 [==============================] - 833s 2s/step - loss: 10.6529\n",
      "Epoch 2/10\n",
      "520/520 [==============================] - 825s 2s/step - loss: 10.4473\n",
      "Epoch 3/10\n",
      "520/520 [==============================] - 833s 2s/step - loss: 10.1308\n",
      "Epoch 4/10\n",
      "520/520 [==============================] - 861s 2s/step - loss: 10.1730\n",
      "Epoch 5/10\n",
      "520/520 [==============================] - 861s 2s/step - loss: 10.0160\n",
      "Epoch 6/10\n",
      "450/520 [========================>.....] - ETA: 1:54 - loss: 10.0566"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\ANlab\\sequence-generator\\gen_data_train.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ANlab/sequence-generator/gen_data_train.ipynb#ch0000018?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ANlab/sequence-generator/gen_data_train.ipynb#ch0000018?line=1'>2</a>\u001b[0m                     epochs \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ANlab/sequence-generator/gen_data_train.ipynb#ch0000018?line=2'>3</a>\u001b[0m                     \u001b[39m# validation_data=validation_dataset,\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ANlab/sequence-generator/gen_data_train.ipynb#ch0000018?line=3'>4</a>\u001b[0m                     verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ANlab/sequence-generator/gen_data_train.ipynb#ch0000018?line=4'>5</a>\u001b[0m                     \u001b[39m# callbacks = callbacks_list,\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ANlab/sequence-generator/gen_data_train.ipynb#ch0000018?line=5'>6</a>\u001b[0m                     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\sonnguyen\\anaconda3\\envs\\bops\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\sonnguyen\\anaconda3\\envs\\bops\\lib\\site-packages\\keras\\engine\\training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/engine/training.py?line=1386'>1387</a>\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/engine/training.py?line=1387'>1388</a>\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/engine/training.py?line=1388'>1389</a>\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/engine/training.py?line=1389'>1390</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/engine/training.py?line=1390'>1391</a>\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sonnguyen\\anaconda3\\envs\\bops\\lib\\site-packages\\keras\\callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=430'>431</a>\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=431'>432</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=432'>433</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=433'>434</a>\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=434'>435</a>\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=435'>436</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=436'>437</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=437'>438</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32mc:\\Users\\sonnguyen\\anaconda3\\envs\\bops\\lib\\site-packages\\keras\\callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=294'>295</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=295'>296</a>\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=296'>297</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=297'>298</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=298'>299</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=299'>300</a>\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sonnguyen\\anaconda3\\envs\\bops\\lib\\site-packages\\keras\\callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=314'>315</a>\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=315'>316</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=317'>318</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=319'>320</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=320'>321</a>\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\sonnguyen\\anaconda3\\envs\\bops\\lib\\site-packages\\keras\\callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=353'>354</a>\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=354'>355</a>\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=355'>356</a>\u001b[0m   hook(batch, logs)\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=357'>358</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=358'>359</a>\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\sonnguyen\\anaconda3\\envs\\bops\\lib\\site-packages\\keras\\callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=1032'>1033</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=1033'>1034</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[1;32mc:\\Users\\sonnguyen\\anaconda3\\envs\\bops\\lib\\site-packages\\keras\\callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=1101'>1102</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=1103'>1104</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=1104'>1105</a>\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=1105'>1106</a>\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/callbacks.py?line=1106'>1107</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\sonnguyen\\anaconda3\\envs\\bops\\lib\\site-packages\\keras\\utils\\tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/utils/tf_utils.py?line=559'>560</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/utils/tf_utils.py?line=560'>561</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/utils/tf_utils.py?line=562'>563</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[1;32mc:\\Users\\sonnguyen\\anaconda3\\envs\\bops\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/util/nest.py?line=909'>910</a>\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/util/nest.py?line=910'>911</a>\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/util/nest.py?line=912'>913</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/util/nest.py?line=913'>914</a>\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/util/nest.py?line=914'>915</a>\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\sonnguyen\\anaconda3\\envs\\bops\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/util/nest.py?line=909'>910</a>\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/util/nest.py?line=910'>911</a>\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/util/nest.py?line=912'>913</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/util/nest.py?line=913'>914</a>\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/util/nest.py?line=914'>915</a>\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\sonnguyen\\anaconda3\\envs\\bops\\lib\\site-packages\\keras\\utils\\tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/utils/tf_utils.py?line=553'>554</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/utils/tf_utils.py?line=554'>555</a>\u001b[0m   \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/utils/tf_utils.py?line=555'>556</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/utils/tf_utils.py?line=556'>557</a>\u001b[0m     t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/utils/tf_utils.py?line=557'>558</a>\u001b[0m   \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/keras/utils/tf_utils.py?line=558'>559</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\sonnguyen\\anaconda3\\envs\\bops\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/framework/ops.py?line=1199'>1200</a>\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/framework/ops.py?line=1200'>1201</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/framework/ops.py?line=1201'>1202</a>\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/framework/ops.py?line=1219'>1220</a>\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/framework/ops.py?line=1220'>1221</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/framework/ops.py?line=1221'>1222</a>\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/framework/ops.py?line=1222'>1223</a>\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/framework/ops.py?line=1223'>1224</a>\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\sonnguyen\\anaconda3\\envs\\bops\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/framework/ops.py?line=1186'>1187</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/framework/ops.py?line=1187'>1188</a>\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/framework/ops.py?line=1188'>1189</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/framework/ops.py?line=1189'>1190</a>\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/sonnguyen/anaconda3/envs/bops/lib/site-packages/tensorflow/python/framework/ops.py?line=1190'>1191</a>\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs = 10,\n",
    "                    # validation_data=validation_dataset,\n",
    "                    verbose = 1,\n",
    "                    # callbacks = callbacks_list,\n",
    "                    initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('D:/ANlab/sequence-generator/CP/best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('D:/ANlab/sequence-generator/CP/best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model = keras.models.Model(\n",
    "    model.get_layer(name=\"Input\").input, model.get_layer(name=\"Softmax\").output\n",
    ")\n",
    "prediction_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "Characters={'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a'}\n",
    "char_to_num = layers.experimental.preprocessing.StringLookup(\n",
    "                  vocabulary=sorted(list(Characters)), num_oov_indices=0, mask_token=None )\n",
    "num_to_char = layers.experimental.preprocessing.StringLookup(\n",
    "                  vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True )\n",
    "\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search\n",
    "    results = K.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][:,:6]\n",
    "    # Iterate over the results and get back the text\n",
    "    output_text = []\n",
    "    for res in results:\n",
    "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode('utf-8')\n",
    "        # res= res.numpy()\n",
    "        output_text.append(res)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "error= 0\n",
    "for batch in train_dataset.take(1):\n",
    "  images = batch['Input']\n",
    "  labels = batch['Label']\n",
    "  # print(images[0], labels[0])\n",
    "  preds = prediction_model.predict(images)\n",
    "  preds= decode_batch_predictions(preds)\n",
    "  orig_texts = []\n",
    "  for label in labels:\n",
    "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode('utf-8')\n",
    "        orig_texts.append(label)\n",
    "  # print(preds)\n",
    "  # print(orig_texts)\n",
    "  for i in range(len(orig_texts)):\n",
    "    # print(preds[i])\n",
    "    # print(orig_texts[i])\n",
    "    if preds[i] == orig_texts[i]:\n",
    "      correct+=1\n",
    "    else:\n",
    "      error += 1\n",
    "print(error)\n",
    "print(correct)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1aee8437345988c8825fe424dfed33296cb482833178e30664e8cbab21b1a22e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('bops')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
